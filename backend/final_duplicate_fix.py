#!/usr/bin/env python3
"""
æœ€ç»ˆé‡å¤è®°å½•ä¿®å¤æ–¹æ¡ˆ
æ ¹æ®é—®é¢˜åˆ†æï¼Œæä¾›å½»åº•çš„è§£å†³æ–¹æ¡ˆ
"""

import json
import os

def analyze_problem():
    """åˆ†æé—®é¢˜æ ¹æº"""
    print("ğŸ” é‡å¤è®°å½•é—®é¢˜åˆ†æ")
    print("=" * 50)
    
    print("ğŸ“‹ é—®é¢˜æè¿°:")
    print("   ç”¨æˆ·åœ¨è¿›è¡Œäººå·¥è¯„ä¼°æ—¶ï¼Œç³»ç»Ÿåˆ›å»ºäº†ä¸¤æ¡å†å²è®°å½•")
    print("   - ç¬¬1æ¡ï¼šAIè¯„ä¼°å®Œæˆæ—¶è‡ªåŠ¨åˆ›å»º")
    print("   - ç¬¬2æ¡ï¼šäººå·¥è¯„ä¼°æ—¶æ„å¤–åˆ›å»º")
    
    print("\nğŸ”¬ æ ¹æœ¬åŸå› :")
    print("   1. å‰ç«¯evaluationService.evaluate()ä¼šè‡ªåŠ¨ä¿å­˜è¯„ä¼°å†å²")
    print("   2. äººå·¥è¯„ä¼°åº”è¯¥åªæ›´æ–°ç°æœ‰è®°å½•ï¼Œä½†å¯èƒ½è§¦å‘äº†æ–°è®°å½•åˆ›å»º")
    print("   3. ç¼ºä¹é‡å¤æ£€æµ‹æœºåˆ¶")

def create_backend_fix():
    """åˆ›å»ºåç«¯ä¿®å¤æ–¹æ¡ˆ"""
    print("\nğŸ”§ ç”Ÿæˆåç«¯ä¿®å¤æ–¹æ¡ˆ...")
    
    backend_fix = '''
# åç«¯ä¿®å¤ï¼šåœ¨evaluation_history_service.pyçš„save_evaluation_resultæ–¹æ³•å¼€å¤´æ·»åŠ é‡å¤æ£€æµ‹

def save_evaluation_result(self, evaluation_data, classification_result=None):
    """
    ä¿å­˜è¯„ä¼°ç»“æœåˆ°å†å²è®°å½•ï¼ˆå¸¦é‡å¤æ£€æµ‹ï¼‰
    """
    try:
        # ====== æ–°å¢ï¼šé‡å¤è®°å½•æ£€æµ‹ ======
        user_input = evaluation_data.get('user_input')
        model_answer = evaluation_data.get('model_answer')
        
        if user_input and model_answer:
            # æ£€æŸ¥æœ€è¿‘5åˆ†é’Ÿå†…æ˜¯å¦æœ‰ç›¸åŒå†…å®¹çš„è®°å½•
            five_minutes_ago = datetime.utcnow() - timedelta(minutes=5)
            existing_record = EvaluationHistory.query.filter(
                EvaluationHistory.user_input == user_input,
                EvaluationHistory.model_answer == model_answer,
                EvaluationHistory.created_at >= five_minutes_ago
            ).first()
            
            if existing_record:
                self.logger.warning(f"æ£€æµ‹åˆ°é‡å¤è®°å½•ï¼Œè¿”å›ç°æœ‰è®°å½•ID: {existing_record.id}")
                return {
                    'success': True,
                    'message': 'æ£€æµ‹åˆ°é‡å¤è®°å½•ï¼Œè¿”å›ç°æœ‰è®°å½•',
                    'history_id': existing_record.id,
                    'data': existing_record.to_dict(),
                    'is_duplicate': True
                }
        # ====== é‡å¤æ£€æµ‹ç»“æŸ ======
        
        # ç»§ç»­åŸæœ‰çš„ä¿å­˜é€»è¾‘...
        history = EvaluationHistory(
            user_input=evaluation_data.get('user_input'),
            model_answer=evaluation_data.get('model_answer'),
            reference_answer=evaluation_data.get('reference_answer'),
            question_time=evaluation_data.get('question_time'),
            evaluation_criteria=evaluation_data.get('evaluation_criteria') or evaluation_data.get('evaluation_criteria_used'),
            total_score=evaluation_data.get('total_score') or evaluation_data.get('score', 0.0),
            dimensions_json=json.dumps(evaluation_data.get('dimensions', {}), ensure_ascii=False),
            reasoning=evaluation_data.get('reasoning'),
            classification_level1=classification_result.get('level1') if classification_result else None,
            classification_level2=classification_result.get('level2') if classification_result else None,
            classification_level3=classification_result.get('level3') if classification_result else None,
            evaluation_time_seconds=evaluation_data.get('evaluation_time_seconds', 0),
            model_used=evaluation_data.get('model_used', 'unknown'),
            raw_response=evaluation_data.get('raw_response'),
            created_at=datetime.utcnow()
        )
        
        db.session.add(history)
        db.session.commit()
        
        self.logger.info(f"æˆåŠŸä¿å­˜è¯„ä¼°å†å²è®°å½•ï¼ŒID: {history.id}")
        
        return {
            'success': True,
            'message': 'è¯„ä¼°å†å²ä¿å­˜æˆåŠŸ',
            'history_id': history.id,
            'data': history.to_dict()
        }
        
    except SQLAlchemyError as e:
        self.logger.error(f"ä¿å­˜è¯„ä¼°å†å²å¤±è´¥: {str(e)}")
        db.session.rollback()
        return {
            'success': False,
            'message': f'ä¿å­˜è¯„ä¼°å†å²å¤±è´¥: {str(e)}'
        }
'''
    
    with open('backend_duplicate_fix.txt', 'w', encoding='utf-8') as f:
        f.write(backend_fix)
    
    print("   âœ… backend_duplicate_fix.txt å·²ç”Ÿæˆ")

def create_frontend_fix():
    """åˆ›å»ºå‰ç«¯ä¿®å¤æ–¹æ¡ˆ"""
    print("\nğŸ”§ ç”Ÿæˆå‰ç«¯ä¿®å¤æ–¹æ¡ˆ...")
    
    frontend_fix = '''
// å‰ç«¯ä¿®å¤1: ä¿®æ”¹evaluationService.jsçš„saveEvaluationHistoryæ–¹æ³•

async saveEvaluationHistory(historyData) {
  try {
    // ====== æ–°å¢ï¼šé‡å¤æ£€æµ‹ ======
    console.log('ä¿å­˜è¯„ä¼°å†å²å‰æ£€æŸ¥é‡å¤...', historyData);
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤ä¿å­˜è¯·æ±‚
    const currentTime = Date.now();
    const requestKey = `${historyData.user_input}|||${historyData.model_answer}`;
    
    // ä½¿ç”¨å†…å­˜ç¼“å­˜é˜²æ­¢çŸ­æ—¶é—´å†…é‡å¤è¯·æ±‚
    if (!this._recentSaves) {
      this._recentSaves = new Map();
    }
    
    const lastSaveTime = this._recentSaves.get(requestKey);
    if (lastSaveTime && (currentTime - lastSaveTime) < 30000) { // 30ç§’å†…
      console.log('æ£€æµ‹åˆ°30ç§’å†…é‡å¤ä¿å­˜è¯·æ±‚ï¼Œè·³è¿‡');
      return { success: true, message: 'è·³è¿‡é‡å¤ä¿å­˜', is_duplicate: true };
    }
    
    // è®°å½•æœ¬æ¬¡ä¿å­˜æ—¶é—´
    this._recentSaves.set(requestKey, currentTime);
    
    // æ¸…ç†è¿‡æœŸçš„ç¼“å­˜ï¼ˆä¿ç•™æœ€è¿‘5åˆ†é’Ÿï¼‰
    const fiveMinutesAgo = currentTime - 300000;
    for (const [key, time] of this._recentSaves.entries()) {
      if (time < fiveMinutesAgo) {
        this._recentSaves.delete(key);
      }
    }
    // ====== é‡å¤æ£€æµ‹ç»“æŸ ======
    
    const response = await this.api.post('/evaluation-history', historyData);
    console.log('è¯„ä¼°å†å²ä¿å­˜æˆåŠŸ');
    return response.data;
  } catch (error) {
    console.error('ä¿å­˜è¯„ä¼°å†å²å¤±è´¥:', error);
    throw new Error('ä¿å­˜è¯„ä¼°å†å²å¤±è´¥');
  }
}

// å‰ç«¯ä¿®å¤2: ä¿®æ”¹EvaluationForm.jsçš„handleHumanEvaluationSubmitæ–¹æ³•
// ç¡®ä¿äººå·¥è¯„ä¼°åªè°ƒç”¨æ›´æ–°æ¥å£ï¼Œä¸è§¦å‘æ–°è®°å½•åˆ›å»º

const handleHumanEvaluationSubmit = async () => {
  // é˜²é‡å¤æäº¤æ£€æŸ¥
  const now = Date.now();
  if (humanEvaluationSubmitting) {
    message.warning('æ­£åœ¨æäº¤ä¸­ï¼Œè¯·å‹¿é‡å¤ç‚¹å‡»');
    return;
  }
  
  if (now - lastSubmissionTime < 3000) {
    message.warning('æäº¤è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•');
    return;
  }
  
  try {
    setHumanEvaluationSubmitting(true);
    setLastSubmissionTime(now);
    setHumanEvaluationLoading(true);
    
    const values = await humanForm.validateFields();
    
    // æ„å»ºäººå·¥è¯„ä¼°æ•°æ®
    const humanData = {
      human_total_score: values.human_total_score,
      human_reasoning: values.human_reasoning,
      evaluator_name: values.evaluator_name || 'è¯„ä¼°ä¸“å®¶'
    };
    
    // æ”¶é›†å„ç»´åº¦åˆ†æ•°
    const humanDimensions = {};
    Object.keys(values).forEach(key => {
      if (key.startsWith('dimension_')) {
        const dimensionKey = key.replace('dimension_', '');
        humanDimensions[dimensionKey] = values[key];
      }
    });
    
    if (Object.keys(humanDimensions).length > 0) {
      humanData.human_dimensions = humanDimensions;
    }
    
    // ====== å…³é”®ä¿®å¤ï¼šåªè°ƒç”¨PUTæ›´æ–°æ¥å£ï¼Œç»ä¸åˆ›å»ºæ–°è®°å½• ======
    console.log('æäº¤äººå·¥è¯„ä¼°æ•°æ®ï¼ˆä»…æ›´æ–°ç°æœ‰è®°å½•ï¼‰:', humanData);
    console.log('ç›®æ ‡è®°å½•ID:', currentHistoryId);
    
    if (!currentHistoryId) {
      throw new Error('æ— æ³•è·å–è¯„ä¼°è®°å½•IDï¼Œè¯·é‡æ–°è¯„ä¼°');
    }
    
    const response = await api.put(`/api/evaluation-history/${currentHistoryId}/human-evaluation`, humanData);
    
    if (response.data.success) {
      message.success('äººå·¥è¯„ä¼°ä¿å­˜æˆåŠŸ');
      setHumanEvaluationVisible(false);
      
      // ====== åˆ é™¤ï¼šä¸å†å°è¯•æ›´æ–°æœ¬åœ°çŠ¶æ€ ======
      // äººå·¥è¯„ä¼°æˆåŠŸåï¼Œæ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“
      // ç”¨æˆ·å¯ä»¥é‡æ–°è¯„ä¼°æŸ¥çœ‹æ›´æ–°åçš„ç»“æœ
      
    } else {
      message.error(response.data.message || 'äººå·¥è¯„ä¼°ä¿å­˜å¤±è´¥');
    }
    
  } catch (error) {
    console.error('äººå·¥è¯„ä¼°æäº¤å¤±è´¥:', error);
    message.error('äººå·¥è¯„ä¼°æäº¤å¤±è´¥ï¼Œè¯·é‡è¯•');
  } finally {
    setHumanEvaluationLoading(false);
    setHumanEvaluationSubmitting(false);
  }
};
'''
    
    with open('frontend_duplicate_fix.txt', 'w', encoding='utf-8') as f:
        f.write(frontend_fix)
    
    print("   âœ… frontend_duplicate_fix.txt å·²ç”Ÿæˆ")

def create_cleanup_script():
    """åˆ›å»ºæ¸…ç†é‡å¤è®°å½•çš„è„šæœ¬"""
    print("\nğŸ§¹ ç”Ÿæˆé‡å¤è®°å½•æ¸…ç†è„šæœ¬...")
    
    cleanup_script = '''#!/usr/bin/env python3
"""
æ¸…ç†ç°æœ‰é‡å¤è®°å½•è„šæœ¬
"""

from app import app
from models.classification import EvaluationHistory, db
from datetime import datetime

def clean_duplicate_records():
    with app.app_context():
        print("ğŸ§¹ å¼€å§‹æ¸…ç†é‡å¤è®°å½•...")
        
        # è·å–æ‰€æœ‰è®°å½•
        all_records = EvaluationHistory.query.all()
        print(f"ğŸ“Š æ€»è®°å½•æ•°: {len(all_records)}")
        
        # æŒ‰å†…å®¹åˆ†ç»„
        content_groups = {}
        for record in all_records:
            key = f"{record.user_input}|||{record.model_answer}"
            if key not in content_groups:
                content_groups[key] = []
            content_groups[key].append(record)
        
        # æ‰¾å‡ºé‡å¤ç»„
        duplicate_groups = {k: v for k, v in content_groups.items() if len(v) > 1}
        
        if not duplicate_groups:
            print("âœ… æ²¡æœ‰å‘ç°é‡å¤è®°å½•")
            return
        
        print(f"ğŸš¨ å‘ç° {len(duplicate_groups)} ç»„é‡å¤è®°å½•")
        
        cleaned_count = 0
        for key, records in duplicate_groups.items():
            # æ’åºï¼šä¼˜å…ˆä¿ç•™äººå·¥ä¿®æ”¹çš„è®°å½•ï¼Œç„¶åæŒ‰IDæ’åº
            records.sort(key=lambda x: (not x.is_human_modified, x.id))
            
            # ä¿ç•™ç¬¬ä¸€æ¡ï¼Œåˆ é™¤å…¶ä½™
            keep_record = records[0]
            delete_records = records[1:]
            
            print(f"ä¿ç•™è®°å½•ID: {keep_record.id}, åˆ é™¤: {[r.id for r in delete_records]}")
            
            # åˆå¹¶äººå·¥è¯„ä¼°æ•°æ®
            for delete_record in delete_records:
                if delete_record.is_human_modified and not keep_record.is_human_modified:
                    keep_record.human_total_score = delete_record.human_total_score
                    keep_record.human_dimensions_json = delete_record.human_dimensions_json
                    keep_record.human_reasoning = delete_record.human_reasoning
                    keep_record.human_evaluation_by = delete_record.human_evaluation_by
                    keep_record.human_evaluation_time = delete_record.human_evaluation_time
                    keep_record.is_human_modified = True
                    keep_record.updated_at = datetime.utcnow()
                
                db.session.delete(delete_record)
                cleaned_count += 1
        
        db.session.commit()
        print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned_count} æ¡é‡å¤è®°å½•")

if __name__ == '__main__':
    clean_duplicate_records()
'''
    
    with open('cleanup_duplicates.py', 'w', encoding='utf-8') as f:
        f.write(cleanup_script)
    
    print("   âœ… cleanup_duplicates.py å·²ç”Ÿæˆ")

def create_deployment_guide():
    """åˆ›å»ºéƒ¨ç½²æŒ‡å—"""
    print("\nğŸ“‹ ç”Ÿæˆéƒ¨ç½²æŒ‡å—...")
    
    guide = '''# é‡å¤è®°å½•é—®é¢˜ä¿®å¤éƒ¨ç½²æŒ‡å—

## ğŸ¯ ä¿®å¤ç›®æ ‡
å½»åº•è§£å†³äººå·¥è¯„ä¼°æ—¶åˆ›å»ºé‡å¤è®°å½•çš„é—®é¢˜

## ğŸ“‹ ä¿®å¤æ­¥éª¤

### 1. åç«¯ä¿®å¤
å°† `backend_duplicate_fix.txt` ä¸­çš„ä»£ç åº”ç”¨åˆ° `backend/services/evaluation_history_service.py`:
- åœ¨ `save_evaluation_result` æ–¹æ³•å¼€å¤´æ·»åŠ é‡å¤æ£€æµ‹é€»è¾‘
- æ£€æŸ¥æœ€è¿‘5åˆ†é’Ÿå†…æ˜¯å¦æœ‰ç›¸åŒå†…å®¹çš„è®°å½•

### 2. å‰ç«¯ä¿®å¤
å°† `frontend_duplicate_fix.txt` ä¸­çš„ä»£ç åº”ç”¨åˆ°å‰ç«¯æ–‡ä»¶:
- ä¿®æ”¹ `frontend/src/services/evaluationService.js` çš„ `saveEvaluationHistory` æ–¹æ³•
- ä¿®æ”¹ `frontend/src/components/EvaluationForm.js` çš„ `handleHumanEvaluationSubmit` æ–¹æ³•

### 3. æ¸…ç†ç°æœ‰é‡å¤è®°å½•
è¿è¡Œæ¸…ç†è„šæœ¬:
```bash
cd backend
python cleanup_duplicates.py
```

### 4. é‡å¯æœåŠ¡
```bash
# é‡å¯åç«¯
cd backend && python app.py

# é‡å¯å‰ç«¯
cd frontend && npm start
```

### 5. éªŒè¯ä¿®å¤æ•ˆæœ
è¿è¡ŒéªŒè¯è„šæœ¬:
```bash
cd backend
python duplicate_monitoring_dashboard.py
```

## ğŸ” ä¿®å¤åŸç†

### åç«¯é˜²æŠ¤
- åœ¨ä¿å­˜è¯„ä¼°ç»“æœå‰æ£€æŸ¥é‡å¤
- 5åˆ†é’Ÿå†…ç›¸åŒå†…å®¹ç›´æ¥è¿”å›ç°æœ‰è®°å½•
- é¿å…æ•°æ®åº“å±‚é¢çš„é‡å¤åˆ›å»º

### å‰ç«¯é˜²æŠ¤
- å†…å­˜ç¼“å­˜é˜²æ­¢30ç§’å†…é‡å¤ä¿å­˜
- äººå·¥è¯„ä¼°åªè°ƒç”¨æ›´æ–°æ¥å£ï¼Œä¸åˆ›å»ºæ–°è®°å½•
- å®Œå–„çš„é˜²é‡å¤æäº¤æœºåˆ¶

### æ¸…ç†ç­–ç•¥
- ä¼˜å…ˆä¿ç•™æœ‰äººå·¥è¯„ä¼°çš„è®°å½•
- åˆå¹¶äººå·¥è¯„ä¼°æ•°æ®åˆ°ä¿ç•™è®°å½•
- åˆ é™¤å¤šä½™çš„é‡å¤è®°å½•

## âœ… éªŒè¯æ ‡å‡†
ä¿®å¤æˆåŠŸçš„æ ‡å¿—ï¼š
- é‡å¤è®°å½•æ•°é‡ä¸º0
- AIè¯„ä¼°+äººå·¥è¯„ä¼°åªäº§ç”Ÿ1æ¡è®°å½•
- å‰ç«¯ç•Œé¢ååº”æ­£å¸¸

## ğŸš¨ æ³¨æ„äº‹é¡¹
- å¤‡ä»½æ•°æ®åº“åå†æ‰§è¡Œæ¸…ç†è„šæœ¬
- ä¿®å¤åå»ºè®®è¿›è¡Œå®Œæ•´çš„åŠŸèƒ½æµ‹è¯•
- ç›‘æ§ç³»ç»Ÿè¿è¡Œä¸€æ®µæ—¶é—´ç¡®ä¿ç¨³å®š
'''
    
    with open('DEPLOYMENT_GUIDE.md', 'w', encoding='utf-8') as f:
        f.write(guide)
    
    print("   âœ… DEPLOYMENT_GUIDE.md å·²ç”Ÿæˆ")

def main():
    """ä¸»å‡½æ•°"""
    analyze_problem()
    create_backend_fix()
    create_frontend_fix()
    create_cleanup_script()
    create_deployment_guide()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ä¿®å¤æ–¹æ¡ˆç”Ÿæˆå®Œæˆï¼")
    print("\nğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("   - backend_duplicate_fix.txt: åç«¯ä¿®å¤ä»£ç ")
    print("   - frontend_duplicate_fix.txt: å‰ç«¯ä¿®å¤ä»£ç ") 
    print("   - cleanup_duplicates.py: é‡å¤è®°å½•æ¸…ç†è„šæœ¬")
    print("   - DEPLOYMENT_GUIDE.md: è¯¦ç»†éƒ¨ç½²æŒ‡å—")
    
    print("\nğŸš€ ä¸‹ä¸€æ­¥:")
    print("1. æŒ‰ç…§ DEPLOYMENT_GUIDE.md åº”ç”¨ä¿®å¤")
    print("2. è¿è¡Œæ¸…ç†è„šæœ¬åˆ é™¤ç°æœ‰é‡å¤è®°å½•")
    print("3. é‡å¯æœåŠ¡å¹¶éªŒè¯ä¿®å¤æ•ˆæœ")

if __name__ == '__main__':
    main() 
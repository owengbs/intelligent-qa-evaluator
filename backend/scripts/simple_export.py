#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆé…ç½®æ•°æ®å¯¼å‡ºè„šæœ¬
ç›´æ¥è¿æ¥SQLiteæ•°æ®åº“ï¼Œå¯¼å‡ºé…ç½®æ•°æ®ä¸ºJSONæ–‡ä»¶
"""

import os
import json
import sqlite3
from datetime import datetime


def connect_database():
    """è¿æ¥SQLiteæ•°æ®åº“"""
    db_path = '../data/qa_evaluator.db'
    if not os.path.exists(db_path):
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return None
    
    try:
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row  # è¿”å›å­—å…¸æ ¼å¼çš„è¡Œ
        return conn
    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        return None


def export_classification_standards(conn):
    """å¯¼å‡ºåˆ†ç±»æ ‡å‡†æ•°æ®"""
    try:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT level1, level1_definition, level2, level3, 
                   level3_definition, examples, is_default
            FROM classification_standards
            ORDER BY level1, level2, level3
        """)
        
        data = []
        for row in cursor.fetchall():
            data.append({
                'level1': row['level1'],
                'level1_definition': row['level1_definition'],
                'level2': row['level2'], 
                'level3': row['level3'],
                'level3_definition': row['level3_definition'],
                'examples': row['examples'],
                'is_default': bool(row['is_default'])
            })
        
        return data
    except Exception as e:
        print(f"âŒ å¯¼å‡ºåˆ†ç±»æ ‡å‡†å¤±è´¥: {e}")
        return []


def export_evaluation_standards(conn):
    """å¯¼å‡ºè¯„ä¼°æ ‡å‡†æ•°æ®"""
    try:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT level2_category, dimension, reference_standard,
                   scoring_principle, max_score, is_default
            FROM evaluation_standards
            ORDER BY level2_category, dimension
        """)
        
        data = []
        for row in cursor.fetchall():
            data.append({
                'level2_category': row['level2_category'],
                'dimension': row['dimension'],
                'reference_standard': row['reference_standard'],
                'scoring_principle': row['scoring_principle'],
                'max_score': row['max_score'],
                'is_default': bool(row['is_default'])
            })
        
        return data
    except Exception as e:
        print(f"âŒ å¯¼å‡ºè¯„ä¼°æ ‡å‡†å¤±è´¥: {e}")
        return []


def save_config_data(classification_data, evaluation_data, output_dir='config_data'):
    """ä¿å­˜é…ç½®æ•°æ®åˆ°JSONæ–‡ä»¶"""
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜åˆ†ç±»æ ‡å‡†
    classification_file = os.path.join(output_dir, 'classification_standards.json')
    with open(classification_file, 'w', encoding='utf-8') as f:
        json.dump({
            'export_time': datetime.now().isoformat(),
            'description': 'åˆ†ç±»æ ‡å‡†é…ç½®æ•°æ® - ç”¨äºå›¢é˜ŸåŒæ­¥',
            'count': len(classification_data),
            'data': classification_data
        }, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… åˆ†ç±»æ ‡å‡†å·²å¯¼å‡º: {classification_file} ({len(classification_data)} æ¡è®°å½•)")
    
    # ä¿å­˜è¯„ä¼°æ ‡å‡†
    evaluation_file = os.path.join(output_dir, 'evaluation_standards.json')
    with open(evaluation_file, 'w', encoding='utf-8') as f:
        json.dump({
            'export_time': datetime.now().isoformat(),
            'description': 'è¯„ä¼°æ ‡å‡†é…ç½®æ•°æ® - ç”¨äºå›¢é˜ŸåŒæ­¥',
            'count': len(evaluation_data),
            'data': evaluation_data
        }, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… è¯„ä¼°æ ‡å‡†å·²å¯¼å‡º: {evaluation_file} ({len(evaluation_data)} æ¡è®°å½•)")
    
    # åˆ›å»ºå¯¼å‡ºæ‘˜è¦
    summary_file = os.path.join(output_dir, 'export_summary.json')
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump({
            'export_time': datetime.now().isoformat(),
            'classification_standards_count': len(classification_data),
            'evaluation_standards_count': len(evaluation_data),
            'total_records': len(classification_data) + len(evaluation_data),
            'files': [
                'classification_standards.json',
                'evaluation_standards.json'
            ],
            'description': 'AIè¯„ä¼°ç³»ç»Ÿé…ç½®æ•°æ®å¯¼å‡ºæ‘˜è¦'
        }, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“ å¯¼å‡ºæ‘˜è¦å·²ä¿å­˜: {summary_file}")
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å¯¼å‡ºAIè¯„ä¼°ç³»ç»Ÿé…ç½®æ•°æ®...")
    print("=" * 50)
    
    # è¿æ¥æ•°æ®åº“
    conn = connect_database()
    if not conn:
        return False
    
    try:
        # å¯¼å‡ºæ•°æ®
        print("ğŸ“‹ å¯¼å‡ºåˆ†ç±»æ ‡å‡†æ•°æ®...")
        classification_data = export_classification_standards(conn)
        
        print("ğŸ“Š å¯¼å‡ºè¯„ä¼°æ ‡å‡†æ•°æ®...")
        evaluation_data = export_evaluation_standards(conn)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        success = save_config_data(classification_data, evaluation_data)
        
        if success:
            print(f"\nğŸ‰ é…ç½®æ•°æ®å¯¼å‡ºå®Œæˆï¼")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {os.path.abspath('config_data')}")
            print(f"ğŸ“Š æ€»è®¡: {len(classification_data) + len(evaluation_data)} æ¡é…ç½®è®°å½•")
            print("\n" + "=" * 50)
            print("ğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œï¼š")
            print("1. å°† config_data/ ç›®å½•æ·»åŠ åˆ°Gitç‰ˆæœ¬æ§åˆ¶")
            print("2. å›¢é˜Ÿæˆå‘˜å¯ä½¿ç”¨ import_config_data.py å¯¼å…¥é…ç½®")
            print("3. é…ç½®æ•°æ®å°†åœ¨å›¢é˜Ÿé—´ä¿æŒåŒæ­¥")
            return True
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºè¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
        return False
    
    finally:
        conn.close()
    
    return False


if __name__ == '__main__':
    import sys
    success = main()
    sys.exit(0 if success else 1) 
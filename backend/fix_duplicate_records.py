#!/usr/bin/env python3
"""
ä¿®å¤é‡å¤è®°å½•é—®é¢˜
1. æ¸…ç†ç°æœ‰é‡å¤è®°å½•
2. æ·»åŠ å‰ç«¯é˜²é‡å¤æäº¤æœºåˆ¶
3. åç«¯æ·»åŠ é‡å¤è®°å½•æ¸…ç†
"""

import json
from datetime import datetime, timedelta
from flask import Flask
from app import app, evaluation_history_service
from models.classification import db, EvaluationHistory

def analyze_and_clean_duplicates():
    """åˆ†æå¹¶æ¸…ç†é‡å¤è®°å½•"""
    print("ğŸ§¹ æ¸…ç†é‡å¤è®°å½•...")
    
    with app.app_context():
        # æ‰¾å‡ºæ‰€æœ‰é‡å¤çš„è®°å½•ç»„
        all_records = EvaluationHistory.query.all()
        duplicate_groups = {}
        
        # æŒ‰é—®é¢˜å’Œç­”æ¡ˆåˆ†ç»„
        for record in all_records:
            key = f"{record.user_input}|||{record.model_answer}"
            if key not in duplicate_groups:
                duplicate_groups[key] = []
            duplicate_groups[key].append(record)
        
        # æ‰¾å‡ºæœ‰é‡å¤çš„ç»„
        duplicated_groups = {k: v for k, v in duplicate_groups.items() if len(v) > 1}
        
        if not duplicated_groups:
            print("âœ… æ²¡æœ‰å‘ç°é‡å¤è®°å½•")
            return
        
        print(f"ğŸš¨ å‘ç° {len(duplicated_groups)} ç»„é‡å¤è®°å½•ï¼Œæ€»è®¡ {sum(len(group) for group in duplicated_groups.values())} æ¡è®°å½•")
        
        cleaned_count = 0
        preserved_count = 0
        
        for key, records in duplicated_groups.items():
            question = records[0].user_input[:50] + "..." if len(records[0].user_input) > 50 else records[0].user_input
            print(f"\nğŸ“ å¤„ç†é‡å¤ç»„: {question}")
            print(f"   é‡å¤è®°å½•æ•°: {len(records)}")
            
            # æ’åºï¼šä¼˜å…ˆä¿ç•™äººå·¥ä¿®æ”¹çš„è®°å½•ï¼Œç„¶åæŒ‰IDæ’åº
            records.sort(key=lambda x: (not x.is_human_modified, x.id))
            
            # ä¿ç•™ç¬¬ä¸€æ¡ï¼ˆæœ€ä¼˜å…ˆçš„ï¼‰è®°å½•
            keep_record = records[0]
            delete_records = records[1:]
            
            print(f"   ä¿ç•™è®°å½•: ID={keep_record.id}, äººå·¥ä¿®æ”¹={keep_record.is_human_modified}")
            
            for delete_record in delete_records:
                print(f"   åˆ é™¤è®°å½•: ID={delete_record.id}, äººå·¥ä¿®æ”¹={delete_record.is_human_modified}")
                
                # å¦‚æœè¦åˆ é™¤çš„è®°å½•æœ‰äººå·¥è¯„ä¼°æ•°æ®ï¼Œåˆå¹¶åˆ°ä¿ç•™çš„è®°å½•ä¸­
                if delete_record.is_human_modified and not keep_record.is_human_modified:
                    print(f"     âš ï¸  è¦åˆ é™¤çš„è®°å½•æœ‰äººå·¥è¯„ä¼°ï¼Œåˆå¹¶åˆ°ä¿ç•™è®°å½•ä¸­")
                    keep_record.human_total_score = delete_record.human_total_score
                    keep_record.human_dimensions_json = delete_record.human_dimensions_json
                    keep_record.human_reasoning = delete_record.human_reasoning
                    keep_record.human_evaluation_by = delete_record.human_evaluation_by
                    keep_record.human_evaluation_time = delete_record.human_evaluation_time
                    keep_record.is_human_modified = True
                    keep_record.updated_at = datetime.utcnow()
                
                db.session.delete(delete_record)
                cleaned_count += 1
            
            preserved_count += 1
        
        try:
            db.session.commit()
            print(f"\nâœ… æ¸…ç†å®Œæˆ:")
            print(f"   - ä¿ç•™è®°å½•: {preserved_count} æ¡")
            print(f"   - åˆ é™¤è®°å½•: {cleaned_count} æ¡")
            print(f"   - æ€»è®¡èŠ‚çœ: {cleaned_count} æ¡è®°å½•")
        except Exception as e:
            db.session.rollback()
            print(f"âŒ æ¸…ç†å¤±è´¥: {e}")

def add_frontend_duplicate_prevention():
    """ä¸ºå‰ç«¯æ·»åŠ é˜²é‡å¤æäº¤æœºåˆ¶"""
    print("\nğŸ”’ ç”Ÿæˆå‰ç«¯é˜²é‡å¤æäº¤è¡¥ä¸...")
    
    frontend_patch = """
// å‰ç«¯é˜²é‡å¤æäº¤æœºåˆ¶è¡¥ä¸
// æ–‡ä»¶ä½ç½®: frontend/src/components/EvaluationForm.js

// 1. åœ¨ç»„ä»¶çŠ¶æ€ä¸­æ·»åŠ æäº¤çŠ¶æ€è·Ÿè¸ª
const [humanEvaluationSubmitting, setHumanEvaluationSubmitting] = useState(false);
const [lastSubmissionTime, setLastSubmissionTime] = useState(0);

// 2. ä¿®æ”¹ handleHumanEvaluationSubmit æ–¹æ³•
const handleHumanEvaluationSubmit = async () => {
  // é˜²é‡å¤æäº¤æ£€æŸ¥
  const now = Date.now();
  if (humanEvaluationSubmitting) {
    message.warning('æ­£åœ¨æäº¤ä¸­ï¼Œè¯·å‹¿é‡å¤ç‚¹å‡»');
    return;
  }
  
  if (now - lastSubmissionTime < 3000) { // 3ç§’å†…ä¸å…è®¸é‡å¤æäº¤
    message.warning('æäº¤è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•');
    return;
  }
  
  try {
    setHumanEvaluationSubmitting(true);
    setLastSubmissionTime(now);
    setHumanEvaluationLoading(true);
    
    const values = await humanForm.validateFields();
    
    // æ„å»ºäººå·¥è¯„ä¼°æ•°æ®
    const humanData = {
      human_total_score: values.human_total_score,
      human_reasoning: values.human_reasoning,
      evaluator_name: values.evaluator_name || 'è¯„ä¼°ä¸“å®¶'
    };
    
    // æ”¶é›†å„ç»´åº¦åˆ†æ•°
    const humanDimensions = {};
    Object.keys(values).forEach(key => {
      if (key.startsWith('dimension_')) {
        const dimensionKey = key.replace('dimension_', '');
        humanDimensions[dimensionKey] = values[key];
      }
    });
    
    if (Object.keys(humanDimensions).length > 0) {
      humanData.human_dimensions = humanDimensions;
    }
    
    // è°ƒç”¨APIæ›´æ–°äººå·¥è¯„ä¼° - åªè°ƒç”¨ä¸€æ¬¡ï¼Œä½¿ç”¨PUTæ–¹æ³•
    console.log('æäº¤äººå·¥è¯„ä¼°æ•°æ®:', humanData);
    const response = await api.put(`/api/evaluation-history/${currentHistoryId}/human-evaluation`, humanData);
    
    if (response.data.success) {
      message.success('äººå·¥è¯„ä¼°ä¿å­˜æˆåŠŸ');
      setHumanEvaluationVisible(false);
      
      // æ›´æ–°å½“å‰æ˜¾ç¤ºçš„ç»“æœ
      setResult(prevResult => ({
        ...prevResult,
        human_total_score: humanData.human_total_score,
        human_reasoning: humanData.human_reasoning,
        is_human_modified: true
      }));
    } else {
      message.error(response.data.message || 'äººå·¥è¯„ä¼°ä¿å­˜å¤±è´¥');
    }
    
  } catch (error) {
    console.error('äººå·¥è¯„ä¼°æäº¤å¤±è´¥:', error);
    message.error('äººå·¥è¯„ä¼°æäº¤å¤±è´¥ï¼Œè¯·é‡è¯•');
  } finally {
    setHumanEvaluationLoading(false);
    setHumanEvaluationSubmitting(false);
  }
};

// 3. ä¿®æ”¹æäº¤æŒ‰é’®ï¼Œæ·»åŠ ç¦ç”¨çŠ¶æ€
// åœ¨ renderHumanEvaluationModal ä¸­çš„ Modal é…ç½®
<Modal
  title={...}
  open={humanEvaluationVisible}
  onCancel={() => setHumanEvaluationVisible(false)}
  onOk={handleHumanEvaluationSubmit}
  okText="ä¿å­˜è¯„ä¼°"
  cancelText="å–æ¶ˆ"
  width={800}
  confirmLoading={humanEvaluationLoading}
  okButtonProps={{
    disabled: humanEvaluationSubmitting, // æ·»åŠ ç¦ç”¨çŠ¶æ€
    loading: humanEvaluationLoading
  }}
>
"""
    
    with open('frontend_duplicate_prevention_patch.txt', 'w', encoding='utf-8') as f:
        f.write(frontend_patch)
    
    print("ğŸ“„ å‰ç«¯è¡¥ä¸å·²ç”Ÿæˆ: frontend_duplicate_prevention_patch.txt")

def add_backend_duplicate_detection():
    """ä¸ºåç«¯æ·»åŠ é‡å¤æ£€æµ‹é€»è¾‘"""
    print("\nğŸ” ç”Ÿæˆåç«¯é‡å¤æ£€æµ‹è¡¥ä¸...")
    
    backend_patch = """
# åç«¯é‡å¤æ£€æµ‹æœºåˆ¶è¡¥ä¸
# æ–‡ä»¶ä½ç½®: backend/services/evaluation_history_service.py

# åœ¨ save_evaluation_result æ–¹æ³•å¼€å§‹å¤„æ·»åŠ é‡å¤æ£€æµ‹
def save_evaluation_result(self, evaluation_data, classification_result=None):
    \"\"\"
    ä¿å­˜è¯„ä¼°ç»“æœåˆ°å†å²è®°å½•ï¼ˆå¸¦é‡å¤æ£€æµ‹ï¼‰
    \"\"\"
    try:
        # é‡å¤æ£€æµ‹ï¼šæ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒçš„é—®é¢˜å’Œç­”æ¡ˆ
        user_input = evaluation_data.get('user_input')
        model_answer = evaluation_data.get('model_answer')
        
        if user_input and model_answer:
            # æŸ¥æ‰¾æœ€è¿‘5åˆ†é’Ÿå†…çš„ç›¸åŒè®°å½•
            five_minutes_ago = datetime.utcnow() - timedelta(minutes=5)
            existing_record = EvaluationHistory.query.filter(
                EvaluationHistory.user_input == user_input,
                EvaluationHistory.model_answer == model_answer,
                EvaluationHistory.created_at >= five_minutes_ago
            ).first()
            
            if existing_record:
                self.logger.warning(f"æ£€æµ‹åˆ°é‡å¤è®°å½•ï¼Œè¿”å›ç°æœ‰è®°å½•ID: {existing_record.id}")
                return {
                    'success': True,
                    'message': 'è¯„ä¼°å†å²å·²å­˜åœ¨ï¼ˆé˜²é‡å¤ï¼‰',
                    'history_id': existing_record.id,
                    'data': existing_record.to_dict(),
                    'is_duplicate': True
                }
        
        # åŸæœ‰çš„ä¿å­˜é€»è¾‘...
        # [ä¿æŒç°æœ‰ä»£ç ä¸å˜]
        
    except SQLAlchemyError as e:
        # é”™è¯¯å¤„ç†é€»è¾‘...
"""
    
    # åç«¯APIæ¥å£æ·»åŠ é‡å¤æ£€æµ‹
    api_patch = """
# æ–‡ä»¶ä½ç½®: backend/app.py
# åœ¨ create_evaluation_history è·¯ç”±ä¸­æ·»åŠ é‡å¤æ£€æµ‹

@app.route('/api/evaluation-history', methods=['POST'])
def create_evaluation_history():
    \"\"\"åˆ›å»ºè¯„ä¼°å†å²è®°å½•ï¼ˆå¸¦é˜²é‡å¤æœºåˆ¶ï¼‰\"\"\"
    try:
        logger.info("æ”¶åˆ°åˆ›å»ºè¯„ä¼°å†å²è¯·æ±‚")
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'ç¼ºå°‘è¯„ä¼°æ•°æ®'}), 400
        
        # æ·»åŠ è¯·æ±‚æŒ‡çº¹æ£€æµ‹
        request_fingerprint = f"{data.get('user_input', '')}|{data.get('model_answer', '')}|{data.get('total_score', 0)}"
        
        # æ£€æŸ¥Redisç¼“å­˜ä¸­æ˜¯å¦æœ‰ç›¸åŒè¯·æ±‚ï¼ˆå¦‚æœä½¿ç”¨Redisï¼‰
        # æˆ–è€…æ£€æŸ¥æ•°æ®åº“ä¸­æœ€è¿‘çš„è®°å½•
        
        result = evaluation_history_service.save_evaluation_result(data)
        
        if result.get('is_duplicate'):
            logger.info(f"é˜²é‡å¤æ£€æµ‹ï¼šè¿”å›ç°æœ‰è®°å½• {result.get('history_id')}")
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"åˆ›å»ºè¯„ä¼°å†å²å¤±è´¥: {str(e)}")
        return jsonify({'error': f'åˆ›å»ºè¯„ä¼°å†å²å¤±è´¥: {str(e)}'}), 500
"""
    
    with open('backend_duplicate_detection_patch.txt', 'w', encoding='utf-8') as f:
        f.write(backend_patch + "\n\n" + api_patch)
    
    print("ğŸ“„ åç«¯è¡¥ä¸å·²ç”Ÿæˆ: backend_duplicate_detection_patch.txt")

def create_monitoring_dashboard():
    """åˆ›å»ºé‡å¤è®°å½•ç›‘æ§ä»ªè¡¨æ¿"""
    print("\nğŸ“Š åˆ›å»ºç›‘æ§ä»ªè¡¨æ¿...")
    
    dashboard_script = """#!/usr/bin/env python3
# é‡å¤è®°å½•ç›‘æ§ä»ªè¡¨æ¿

from app import app
from models.classification import EvaluationHistory
from datetime import datetime, timedelta
from collections import defaultdict

def show_duplicate_dashboard():
    with app.app_context():
        print("ğŸ“Š é‡å¤è®°å½•ç›‘æ§ä»ªè¡¨æ¿")
        print("=" * 50)
        
        # æ€»ä½“ç»Ÿè®¡
        total_records = EvaluationHistory.query.count()
        human_modified = EvaluationHistory.query.filter(EvaluationHistory.is_human_modified == True).count()
        
        print(f"ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»è®°å½•æ•°: {total_records}")
        print(f"   äººå·¥ä¿®æ”¹è®°å½•: {human_modified}")
        print(f"   çº¯AIè®°å½•: {total_records - human_modified}")
        
        # æœ€è¿‘24å°æ—¶çš„è®°å½•
        last_24h = datetime.utcnow() - timedelta(hours=24)
        recent_records = EvaluationHistory.query.filter(
            EvaluationHistory.created_at >= last_24h
        ).all()
        
        print(f"\\nâ° æœ€è¿‘24å°æ—¶:")
        print(f"   æ–°å¢è®°å½•: {len(recent_records)}")
        
        # æ£€æŸ¥æœ€è¿‘çš„é‡å¤
        recent_groups = defaultdict(list)
        for record in recent_records:
            key = f"{record.user_input}|||{record.model_answer}"
            recent_groups[key].append(record)
        
        recent_duplicates = {k: v for k, v in recent_groups.items() if len(v) > 1}
        
        if recent_duplicates:
            print(f"   âš ï¸  å‘ç°æœ€è¿‘é‡å¤: {len(recent_duplicates)} ç»„")
            for key, records in recent_duplicates.items():
                question = records[0].user_input[:30] + "..."
                print(f"     {question}: {len(records)} æ¡è®°å½•")
        else:
            print(f"   âœ… æ— æœ€è¿‘é‡å¤è®°å½•")
        
        # æŒ‰å°æ—¶ç»Ÿè®¡åˆ›å»ºé¢‘ç‡
        hour_stats = defaultdict(int)
        for record in recent_records:
            hour = record.created_at.hour
            hour_stats[hour] += 1
        
        print(f"\\nğŸ“… æœ€è¿‘24å°æ—¶åˆ›å»ºé¢‘ç‡:")
        for hour in sorted(hour_stats.keys()):
            print(f"   {hour:02d}:00-{hour:02d}:59: {hour_stats[hour]} æ¡è®°å½•")

if __name__ == '__main__':
    show_duplicate_dashboard()
"""
    
    with open('duplicate_monitoring_dashboard.py', 'w', encoding='utf-8') as f:
        f.write(dashboard_script)
    
    print("ğŸ“„ ç›‘æ§ä»ªè¡¨æ¿å·²åˆ›å»º: duplicate_monitoring_dashboard.py")

def create_fix_summary():
    """åˆ›å»ºä¿®å¤æ€»ç»“"""
    print("\nğŸ“‹ ä¿®å¤æ€»ç»“")
    print("=" * 50)
    
    summary = """
# é‡å¤è®°å½•é—®é¢˜ä¿®å¤æ€»ç»“

## ğŸ” é—®é¢˜åˆ†æ
1. **é‡å¤è®°å½•ç¡®å®å­˜åœ¨**ï¼šå‘ç°å¤šç»„é‡å¤çš„è¯„ä¼°è®°å½•
2. **åç«¯é€»è¾‘æ­£å¸¸**ï¼šäººå·¥è¯„ä¼°æ›´æ–°æœºåˆ¶å·¥ä½œæ­£å¸¸ï¼Œä¸ä¼šåˆ›å»ºæ–°è®°å½•
3. **å¯èƒ½åŸå› **ï¼šå‰ç«¯é‡å¤æäº¤ã€ç½‘ç»œé‡è¯•ã€ç”¨æˆ·æ“ä½œå¯¼è‡´

## ğŸ› ï¸ ä¿®å¤æ–¹æ¡ˆ

### 1. æ•°æ®æ¸…ç† âœ…
- è¿è¡Œ `python fix_duplicate_records.py` è‡ªåŠ¨æ¸…ç†é‡å¤è®°å½•
- ä¼˜å…ˆä¿ç•™æœ‰äººå·¥è¯„ä¼°çš„è®°å½•
- åˆå¹¶äººå·¥è¯„ä¼°æ•°æ®åˆ°ä¿ç•™çš„è®°å½•ä¸­

### 2. å‰ç«¯é˜²é‡å¤æœºåˆ¶
- æ·»åŠ æäº¤çŠ¶æ€è·Ÿè¸ª (`humanEvaluationSubmitting`)
- å®ç°3ç§’é˜²é‡å¤é—´éš”
- æŒ‰é’®ç¦ç”¨çŠ¶æ€é˜²æ­¢é‡å¤ç‚¹å‡»
- åº”ç”¨è¡¥ä¸ï¼š`frontend_duplicate_prevention_patch.txt`

### 3. åç«¯é‡å¤æ£€æµ‹
- 5åˆ†é’Ÿå†…ç›¸åŒå†…å®¹æ£€æµ‹
- è¿”å›ç°æœ‰è®°å½•è€Œéåˆ›å»ºæ–°è®°å½•
- APIçº§åˆ«çš„é˜²é‡å¤æœºåˆ¶
- åº”ç”¨è¡¥ä¸ï¼š`backend_duplicate_detection_patch.txt`

### 4. ç›‘æ§å·¥å…·
- `duplicate_monitoring_dashboard.py`ï¼šå®æ—¶ç›‘æ§é‡å¤æƒ…å†µ
- `monitor_records.py`ï¼šæ‰‹åŠ¨æµ‹è¯•ç›‘æ§

## ğŸ“‹ éƒ¨ç½²æ­¥éª¤

1. **ç«‹å³æ¸…ç†ç°æœ‰é‡å¤è®°å½•**ï¼š
   ```bash
   python fix_duplicate_records.py
   ```

2. **åº”ç”¨å‰ç«¯è¡¥ä¸**ï¼š
   - å‚è€ƒ `frontend_duplicate_prevention_patch.txt`
   - ä¿®æ”¹ `frontend/src/components/EvaluationForm.js`

3. **åº”ç”¨åç«¯è¡¥ä¸**ï¼š
   - å‚è€ƒ `backend_duplicate_detection_patch.txt`
   - ä¿®æ”¹ç›¸å…³åç«¯æ–‡ä»¶

4. **éƒ¨ç½²åéªŒè¯**ï¼š
   ```bash
   python duplicate_monitoring_dashboard.py
   python monitor_records.py
   ```

## ğŸ¯ é¢„æœŸæ•ˆæœ
- âœ… æ¶ˆé™¤ç°æœ‰é‡å¤è®°å½•
- âœ… é˜²æ­¢æ–°çš„é‡å¤è®°å½•äº§ç”Ÿ
- âœ… æå‡ç³»ç»Ÿæ•°æ®è´¨é‡
- âœ… æ”¹å–„ç”¨æˆ·ä½“éªŒ

## ğŸ“Š ç›‘æ§æŒ‡æ ‡
- æ€»è®°å½•æ•°é‡å˜åŒ–
- é‡å¤è®°å½•æ£€æµ‹ç‡
- ç”¨æˆ·é‡å¤æäº¤æ‹¦æˆªç‡
- ç³»ç»Ÿæ€§èƒ½å½±å“ï¼ˆåº”è¯¥å¾ˆå°ï¼‰
"""
    
    with open('DUPLICATE_RECORDS_FIX_SUMMARY.md', 'w', encoding='utf-8') as f:
        f.write(summary)
    
    print("ğŸ“„ ä¿®å¤æ€»ç»“å·²åˆ›å»º: DUPLICATE_RECORDS_FIX_SUMMARY.md")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ é‡å¤è®°å½•ä¿®å¤å·¥å…·")
    print("=" * 60)
    
    # 1. åˆ†æå¹¶æ¸…ç†ç°æœ‰é‡å¤è®°å½•
    analyze_and_clean_duplicates()
    
    # 2. ç”Ÿæˆå‰ç«¯é˜²é‡å¤æœºåˆ¶
    add_frontend_duplicate_prevention()
    
    # 3. ç”Ÿæˆåç«¯é‡å¤æ£€æµ‹é€»è¾‘
    add_backend_duplicate_detection()
    
    # 4. åˆ›å»ºç›‘æ§å·¥å…·
    create_monitoring_dashboard()
    
    # 5. åˆ›å»ºä¿®å¤æ€»ç»“
    create_fix_summary()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ é‡å¤è®°å½•ä¿®å¤å®Œæˆï¼")
    print("\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - frontend_duplicate_prevention_patch.txt (å‰ç«¯è¡¥ä¸)")
    print("  - backend_duplicate_detection_patch.txt (åç«¯è¡¥ä¸)")
    print("  - duplicate_monitoring_dashboard.py (ç›‘æ§ä»ªè¡¨æ¿)")
    print("  - DUPLICATE_RECORDS_FIX_SUMMARY.md (ä¿®å¤æ€»ç»“)")
    
    print("\nğŸš€ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("1. åº”ç”¨å‰ç«¯å’Œåç«¯è¡¥ä¸")
    print("2. é‡å¯å‰åç«¯æœåŠ¡")
    print("3. è¿è¡Œç›‘æ§å·¥å…·éªŒè¯æ•ˆæœ")
    print("4. è¿›è¡Œå®Œæ•´çš„è¯„ä¼°æµ‹è¯•")

if __name__ == '__main__':
    main() 